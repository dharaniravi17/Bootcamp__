{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff287c29-f7f0-401b-8606-883fe0b9bbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (42000, 785)\n",
      "Test data shape: (42000, 785)\n",
      "Determined image size: 28x28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dharani Ravi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 29ms/step - accuracy: 0.1045 - loss: 2.3631 - val_accuracy: 0.0970 - val_loss: 2.3065\n",
      "Epoch 2/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.1053 - loss: 2.3066 - val_accuracy: 0.0984 - val_loss: 2.3058\n",
      "Epoch 3/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 27ms/step - accuracy: 0.1059 - loss: 2.3076 - val_accuracy: 0.1036 - val_loss: 2.3065\n",
      "Epoch 4/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 35ms/step - accuracy: 0.1047 - loss: 2.3078 - val_accuracy: 0.1036 - val_loss: 2.3054\n",
      "Epoch 5/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 27ms/step - accuracy: 0.1060 - loss: 2.3068 - val_accuracy: 0.1115 - val_loss: 2.3060\n",
      "Epoch 6/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 27ms/step - accuracy: 0.1031 - loss: 2.3073 - val_accuracy: 0.1036 - val_loss: 2.3150\n",
      "Epoch 7/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 27ms/step - accuracy: 0.1045 - loss: 2.3089 - val_accuracy: 0.0984 - val_loss: 2.3084\n",
      "Epoch 8/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 35ms/step - accuracy: 0.1052 - loss: 2.3074 - val_accuracy: 0.1115 - val_loss: 2.3088\n",
      "Epoch 9/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 36ms/step - accuracy: 0.1069 - loss: 2.3077 - val_accuracy: 0.0904 - val_loss: 2.3061\n",
      "Epoch 10/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.1005 - loss: 2.3078 - val_accuracy: 0.0984 - val_loss: 2.3089\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n\u001b[0;32m     44\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m [layer\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, layers\u001b[38;5;241m.\u001b[39mConv2D)]\n\u001b[1;32m---> 45\u001b[0m activation_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39mlayer_outputs)\n\u001b[0;32m     46\u001b[0m feature_maps \u001b[38;5;241m=\u001b[39m activation_model\u001b[38;5;241m.\u001b[39mpredict(X_test[:\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:254\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_attribute_at_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "train_path = \"C:\\\\Users\\\\Dharani Ravi\\\\Downloads\\\\digit-recognizer\\\\train.csv\"\n",
    "test_path = \"C:\\\\Users\\\\Dharani Ravi\\\\Downloads\\\\digit-recognizer\\\\train.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "\n",
    "num_pixels_train = train_df.shape[1] - 1  \n",
    "num_pixels_test = test_df.shape[1] - 1  \n",
    "\n",
    "if num_pixels_train != num_pixels_test:\n",
    "    raise ValueError(\"Mismatch in image sizes between train and test datasets.\")\n",
    "\n",
    "img_size = int(np.sqrt(num_pixels_train)) \n",
    "print(f\"Determined image size: {img_size}x{img_size}\")\n",
    "\n",
    "X_train = train_df.iloc[:, 1:].values.reshape(-1, img_size, img_size, 1) / 255.0  \n",
    "y_train = tf.keras.utils.to_categorical(train_df.iloc[:, 0], num_classes=10)\n",
    "\n",
    "X_test = test_df.iloc[:, 1:].values.reshape(-1, img_size, img_size, 1) / 255.0\n",
    "y_test = tf.keras.utils.to_categorical(test_df.iloc[:, 0], num_classes=10)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(3, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(784, activation='relu'), \n",
    "    layers.Dense(10, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.05),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers if isinstance(layer, layers.Conv2D)]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "feature_maps = activation_model.predict(X_test[:1])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(feature_maps[0][:, :, i], cmap='gray')\n",
    "    plt.title(f\"Feature Map {i+1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy'][-1]\n",
    "print(f\"Initial Training Accuracy: {accuracy:.4f}\")\n",
    "print(\"Feature maps show different extracted patterns from the dataset images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfe231-f171-486d-a70a-801084610c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
